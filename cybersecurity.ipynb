{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cdbdd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d936fd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required resources\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7d513d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99904039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sentence Tokenization\n",
    "def split_into_sentences(text):\n",
    "    return sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35c36a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create Frequency Matrix for each sentence\n",
    "def create_frequency_matrix(sentences):\n",
    "    freq_matrix = {}\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent.lower())\n",
    "        words = [ps.stem(word) for word in words if word.isalnum() and word not in stop_words]\n",
    "        freq_table = {}\n",
    "        for word in words:\n",
    "            freq_table[word] = freq_table.get(word, 0) + 1\n",
    "        freq_matrix[sent] = freq_table\n",
    "    return freq_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d50959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Term Frequency (TF) calculation\n",
    "def create_tf_matrix(freq_matrix):\n",
    "    tf_matrix = {}\n",
    "    for sent, freq_table in freq_matrix.items():\n",
    "        tf_table = {}\n",
    "        total_words = sum(freq_table.values())\n",
    "        for word, count in freq_table.items():\n",
    "            tf_table[word] = count / total_words\n",
    "        tf_matrix[sent] = tf_table\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "312b8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Document per word table\n",
    "def create_documents_per_word(freq_matrix):\n",
    "    word_doc_table = {}\n",
    "    for freq_table in freq_matrix.values():\n",
    "        for word in freq_table:\n",
    "            word_doc_table[word] = word_doc_table.get(word, 0) + 1\n",
    "    return word_doc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae45480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Inverse Document Frequency (IDF) calculation\n",
    "def create_idf_matrix(freq_matrix, doc_per_words, total_docs):\n",
    "    idf_matrix = {}\n",
    "    for sent, freq_table in freq_matrix.items():\n",
    "        idf_table = {}\n",
    "        for word in freq_table:\n",
    "            idf_table[word] = math.log10(total_docs / float(doc_per_words[word]))\n",
    "        idf_matrix[sent] = idf_table\n",
    "    return idf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f36fc1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: TF-IDF Calculation\n",
    "def create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = {}\n",
    "    for sent, tf_table in tf_matrix.items():\n",
    "        tfidf_table = {}\n",
    "        for word, tf_val in tf_table.items():\n",
    "            idf_val = idf_matrix[sent].get(word, 0)\n",
    "            tfidf_table[word] = tf_val * idf_val\n",
    "        tf_idf_matrix[sent] = tfidf_table\n",
    "    return tf_idf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b663858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Score Sentences\n",
    "def score_sentences(tfidf_matrix):\n",
    "    sentence_scores = {}\n",
    "    for sent, tfidf_table in tfidf_matrix.items():\n",
    "        total_score = sum(tfidf_table.values())\n",
    "        sentence_scores[sent] = total_score / len(tfidf_table) if tfidf_table else 0\n",
    "    return sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61d04aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Find threshold and generate summary\n",
    "def find_average_score(sentence_scores):\n",
    "    return sum(sentence_scores.values()) / len(sentence_scores)\n",
    "\n",
    "def generate_summary(sentences, sentence_scores, threshold):\n",
    "    summary = [sent for sent in sentences if sentence_scores.get(sent, 0) >= threshold]\n",
    "    return \" \".join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e0aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98215475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN FUNCTION\n",
    "def summarize_text(text):\n",
    "    sentences = split_into_sentences(text)\n",
    "    freq_matrix = create_frequency_matrix(sentences)\n",
    "    tf_matrix = create_tf_matrix(freq_matrix)\n",
    "    doc_per_words = create_documents_per_word(freq_matrix)\n",
    "    idf_matrix = create_idf_matrix(freq_matrix, doc_per_words, len(sentences))\n",
    "    tfidf_matrix = create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
    "    sentence_scores = score_sentences(tfidf_matrix)\n",
    "    threshold = find_average_score(sentence_scores)\n",
    "    summary = generate_summary(sentences, sentence_scores, threshold)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b0246d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a5b588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary ===\n",
      "NLP is widely used in chatbots, machine translation, sentiment analysis, and text summarization. Its popularity has grown due to advancements in deep learning and availability of large datasets.\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "Natural language processing (NLP) is a sub-field of artificial intelligence (AI) that is focused on enabling machines to understand and respond to text or voice data. \n",
    "It involves several challenges including speech recognition, natural language understanding, and natural language generation. \n",
    "NLP is widely used in chatbots, machine translation, sentiment analysis, and text summarization. \n",
    "Its popularity has grown due to advancements in deep learning and availability of large datasets.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_text(sample_text)\n",
    "print(\"=== Summary ===\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "074dbae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 492\n"
     ]
    }
   ],
   "source": [
    "print(len(summary),len(sample_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
